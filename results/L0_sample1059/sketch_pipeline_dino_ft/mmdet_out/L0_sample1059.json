{
    "bboxes": [
        [
            0.25290055338541667,
            0.6783559977213541,
            0.43742183430989584,
            0.850900390625
        ],
        [
            0.34723042805989585,
            0.237930419921875,
            0.5045880126953125,
            0.3835029296875
        ],
        [
            0.013577401479085286,
            0.8499930826822917,
            0.5320479736328125,
            0.9966649576822917
        ],
        [
            0.4669327392578125,
            0.7319677734375,
            0.6650528564453125,
            0.9694449055989584
        ],
        [
            0.09635692342122396,
            0.4309261474609375,
            0.18111328125,
            0.5139984537760417
        ],
        [
            0.01321649424235026,
            0.8500857747395834,
            0.5103215738932292,
            0.9967574869791667
        ],
        [
            0.014043003082275391,
            0.8501361490885416,
            0.376955322265625,
            0.996724609375
        ],
        [
            0.3469613850911458,
            0.237622314453125,
            0.504811279296875,
            0.3834151204427083
        ],
        [
            0.09637279256184896,
            0.4307826334635417,
            0.18120452880859375,
            0.5140949300130209
        ]
    ],
    "labels": [
        " bird",
        " illustration",
        " drawing",
        " bird",
        " cock",
        " drawing",
        " drawing",
        "animal",
        " white"
    ],
    "scores": [
        0.6365392208099365,
        0.4476887285709381,
        0.3992760479450226,
        0.3575337529182434,
        0.33012863993644714,
        0.288193017244339,
        0.24078631401062012,
        0.21034851670265198,
        0.205888032913208
    ],
    "model_info": {
        "model_config": "/mnt/sda/miatang/projects/stroke-label/extern/mmdetection/ours_weights/base_cat_full_ft_allclass_val/intersect_full_ft_all_class_val.py",
        "weights": "/mnt/sda/miatang/projects/stroke-label/extern/mmdetection/ours_weights/base_cat_full_ft_allclass_val/best_coco_bbox_mAP_iter_47000.pth",
        "device": "cuda:0",
        "score_threshold": 0.2
    }
}